---
permalink: /
title: "Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello! My name is Saurabh Garg and I am a fourth year PhD student at Machine Learning Department at CMU where I am advised by [Prof. Zachary Lipton](http://zacklipton.com/) and [Prof. Siva Balakrishnan](http://www.stat.cmu.edu/~siva/). I am broadly interested in building **robust and deployable machine learning systems** under distribution shift. Machine learning algorithms are typically developed and evaluated under simplistic assumptions that are often violated in practice. I am interested in understanding the behavior of machine learning models in real-world scenarios and building provable methods to make progress towards relaxing simplifying assumptions in order to make robust and trustworthy models.

I did my undergrad from IIT Bombay, India with major and honors in CS and minors in Applied Statitics in 2018. After that, I spent one amazing year at Samsung Headquaters, Korea. In the past, I have worked with [Prof. Preethi Jyothi](https://www.cse.iitb.ac.in/~pjyothi), [Prof. Soumen Chakrabarti](https://www.cse.iitb.ac.in/~soumen), [Prof. Suyash Awate](https://www.cse.iitb.ac.in/~suyash). 

<!---
I did my undergrad from IIT Bombay, India with major and honors in CS and minors in Applied Statitics in 2018. After that, I spent one amazing year at Samsung Headquaters, Korea. In the past, I have worked with [Prof. Suyash Awate](https://www.cse.iitb.ac.in/~suyash) on building statistical machine learning algorithms for exact MCMC samspling as a part of my Bachelor's thesis. During my stay at IITB, I have also spent major time working with [Prof. Preethi Jyothi](https://www.cse.iitb.ac.in/~pjyothi) on the problem of building robust language models for code switched speech. I was also fortunate to work with [Prof. Soumen Chakrabarti](https://www.cse.iitb.ac.in/~soumen) on building interpretable question answering systems using KG and corpus. 

-->

---

### **Updates**

<style>
table, tr, td {
    border: none;
}
</style>
<div style="height:250px;overflow:auto;border:0px;border-collapse: collapse;" >
<table  border="none" style="border:0px;border-collapse: collapse;" rules="none" >
<colgroup>
       <col span="1" style="width: 12%;">
       <col span="1" style="width: 88%;">
</colgroup>
<tr><td> <b> Sept 2022:</b> </td> <td> Our work on (i) <a href="https://saurabhgarg1996.github.io/publications/">Domain adaptation under Open Set Label Shift</a>, (ii) <a href="https://saurabhgarg1996.github.io/publications/">Unsupervised Learning under Latent Label Shift</a>, and (iii) <a href="https://saurabhgarg1996.github.io/publications">Characterizing Datapoints via Second-Split Forgetting</a> got accepted at NeurIPS 2022.</td></tr>  
<tr><td> <b> July 2022:</b> </td> <td> We are organizing <a href="https://sites.google.com/view/icml-2022-pods">Principles of Distribution Shift (PODS)</a> workshop at ICML, 2022. </td> </tr>  
<tr><td> <b> March 2022:</b> </td> <td> Honored to receive the <a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards/phd-fellowship">JP Morgan AI PhD Fellowship</a> and <a href="https://www.amazon.science/academic-engagements/new-amazon-graduate-research-fellows-announced-at-carnegie-mellon">Amazon Graduate Fellowship</a>. </td> </tr>  
<tr><td> <b> Feb 2022:</b> </td> <td> Code for <a href="https://github.com/acmi-lab/PU_learning">PU learning</a> and <a href="https://github.com/acmi-lab/RATT_generalization_bound">RATT</a> is out now.</td></tr>
<tr><td> <b> Jan 2022:</b> </td> <td> Work on investigate methods to predict target domain performance under distribution shift was accepted at ICLR 2022. <a href="https://arxiv.org/abs/2201.04234">[Arxiv link]</a></td></tr>
<tr><td> <b> Sept 2021:</b> </td> <td> Work on learning from positive and unlabeled data accepted at NeurIPS 2021 as a Spotlight!. <a href="https://arxiv.org/abs/2111.00980">[Arxiv link]</a></td></tr>
<tr><td> <b> May 2021:</b> </td> <td> Two papers at ICML: (i) Work on obtaining generalization bound with unlabeled data got accepted as Long talk at ICML 2021 <a href="https://arxiv.org/abs/2105.00303">[Paper]</a>; (ii) Work on understanding heavy tails in PPO to appear as Short Talk  at ICML 2021 <a href="https://arxiv.org/abs/2102.10264">[Paper]</a>.</td></tr>
<tr><td><b> April 2021:</b> </td> <td> Our work on obtaining generalization gaurantees with unlabeled data will be presented at <a href="https://sites.google.com/connect.hku.hk/robustml-2021/">RobustML Workshop</a> at ICLR 2021 <a href="https://arxiv.org/abs/2105.00303">[Paper]</a> <a href="https://drive.google.com/file/d/1H25csKq622EDMtw2en-aDQxqNcP1Mcdg/view?usp=sharing">[Poster]</a>.  </td></tr> 
<tr><td><b> April 2021:</b> </td> <td> Our work on understanding behaviour of gradients in PPO will be presented at <a href="https://sites.google.com/view/sedl-workshop/">SEDL Workshop</a> at ICLR 2021. <a href="https://arxiv.org/abs/2102.10264">[Paper]</a> <a href="https://drive.google.com/file/d/1Uvcuqbcv9w2NQNSVoOdoLsDcyf2FpBc3/view?usp=sharing">[Talk]</a> <a href="https://drive.google.com/file/d/1U2GxKvBqEC32vY-DZxnzHT80rj8fePqr/view?usp=sharing">[Poster]</a>. </td></tr> 
<tr><td><b> Feb 2021:</b> </td> <td> Excited to be interning with <a href="https://research.google/people/HanieSedghi/">Hanie Sedghi</a> and <a href="https://www.neyshabur.net/">Behnam Neyshabur</a> at Google Brain during Summer 21.</td> </tr>
<tr><td><b> Feb 2021:</b> </td> <td> New work on understanding behaviour of gradients in PPO is out on <a href="https://arxiv.org/abs/2102.10264">arxiv</a>. </td> </tr>
<tr><td><b> Sept 2020:</b> </td> <td> Our work on label shift got accepted at NeurIPs 2020  <a href="https://arxiv.org/abs/2003.07554">[Paper]</a> <a href="https://drive.google.com/file/d/13hpynIYM69nSRqj-7CHdvEdG7amC9phy/view?usp=sharing">[Poster]</a>. </td> </tr>
<tr><td> <b> July 2020:</b> </td> <td> Our work on label shift estimation was accepted as Oral at <a href="https://sites.google.com/view/udlworkshop2020/">ICML UDL 2020</a> <a href="https://slideslive.com/38930578/a-unified-view-of-label-shift-estimation?ref=speaker-37449-latest">[Talk]</a> <a href="https://arxiv.org/abs/2003.07554">[Full Paper]</a>. </td> </tr>
<tr><td><b> April 2020:</b> </td> <td> Our work on Neural Architecture for Question Answering was an invited Oral at <a href="https://ecir2020.org/">ECIR 2020</a> <a href="https://youtu.be/cVZ3Qj8sJCk?t=24540">[Talk]</a>.  </td> </tr>
<tr><td><b> June 2019:</b> </td> <td> I will be joining CMU ML Ph.D. in fall 2019. </td></tr> 
<tr><td><b> April 2019:</b></td> <td> My B.Tech thesis titled <a href="https://www.sciencedirect.com/science/article/pii/S1361841518307382?dgcid=rss_sd_all">"Estimating Uncertainty in MRF-based Image Segmentation: An Exact-MCMC Approach"</a> got accepted at Medical Image Analysis 2019 journal </td> </tr>
<tr><td><b> Dec. 2018:</b></td> <td> Received Excellence in Research Award from CSE dept, IIT Bombay</td> </tr>
<tr><td><b> Nov. 2018:</b></td> <td> Presented my paper<a href="https://arxiv.org/abs/1809.01962">"Code-Switched Language models using Dual RNNs and Same-Source Pretraining"</a> at EMNLP 2018, Brussels <a href="files/EMNLP_poster_2018.pdf">(poster)</a></td> </tr>
<tr><td><b> Oct. 2018:</b></td> <td> Paper titled <a href="https://arxiv.org/abs/1706.00973">"Neural Architecture for Question Answering Using a Knowledge Graph and Web Corpus"</a> got accepted at Information Retrieval Journal</td></tr> 
<tr><td><b> Sept. 2018:</b></td> <td> Moved to Suwon, South Korea and joined Samsung Research Korea as Engineer</td> </tr>
<tr><td><b> Sept. 2018:</b></td> <td> Presented my paper <a href="https://arxiv.org/abs/1711.01048" >"Dual Language Models for Code Mixed Speech Recognition"</a> at Interspeech 2018, Hyderabad <a href="files/Interspeech_poster_2018.pdf">(poster)</a></td></tr> 
<tr><td><b> Aug. 2018:</b></td> <td> Graduated from IIT Bombay. </td> </tr>
<tr><td><b> May 2018:</b></td> <td> Paper titled <a href="https://link.springer.com/chapter/10.1007/978-3-030-00928-1_76" > "Uncertainty Estimation in Segmentation with Perfect MCMC Sampling in Bayesian MRFs" </a> got accepted at MICCAI, 2018 <a href = "files/poster_miccai_unc_2018.pdf" >(poster)</a></td></tr>
<tr><td><b> Dec 2018:</b></td> <td> Invited to spend two weeks at Microsoft Research India to work on Indian language technologies with Prof. Preethi Jyothi</td></tr>
<tr><td><b> May 2017:</b></td> <td> Internship @ Samsung Research Korea </td></tr>
<tr><td><b> May 2016:</b></td> <td> Internship at Purdue Univeristy, US advised by Prof. Alex Pothen</td></tr>
<tr><td><b> July 2015:</b></td> <td> Changed branch from Electrical Engineering to Computer Science Engineering</td></tr> 
<tr><td><b> July 2014:</b></td> <td> Joined IIT Bombay</td></tr> 
</table>
